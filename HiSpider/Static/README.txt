静态网页爬虫项目

第一阶段：实现给给定任意网页，提取信息并智能生成数据结构：完成
已完成：
    字典列表的储存，
    日志的生成，
    发送请求获得HTML，
    对HTML进行解析
    将HTML标签按照子层级数目从大到小排序
    过滤标签
    生成键值对应的字典列表
    保存字典
第二阶段：人工介入与程序共同过滤信息，就是一个分类的过程
已完成：            
未完成：
BUG：

第三阶段：分析数据

第四阶段：UI

第五阶段：机器学习过滤信息




# =============================================================================
# 1：请求
# 2：解析
# 3：保存
# =============================================================================

# =============================================================================
# 通过Requests抓取到静态页面的HTML代码，后面再进行解析
# 功能：GET/POST请求，会话，上传文件，SSL等认证，登录，代理，队列
# =============================================================================

 ==============================================================================
 什么是爬虫？
     互联网海量的数据，用一般的方式已经无法满足对数据的需求了，当你打开浏览器在百度谷歌搜索关键词的时候你就已经间接的使用了爬虫，只不过它并不属于你
     关键词通过通过互联网发送到百度的服务器，这一过程称为Requests（请求），然后百度服务器给你一个Response（响应）
     爬虫其实就是直接向服务器发送Requests，而不需要你的浏览器
     
 
 为什么使用爬虫？
     假设：
         市场调查
         刷评论
         获取资源
     你可能需要：
         点击网页上万次
     或者你有一个通用爬虫，能帮你一键：
         上传
         下载
 怎么编写爬虫？
     简单来说：
         发送请求
         获得服务器发送过来的html代码
         解析html代码，筛选获取有效数据
         保存数据
         分析数据
 ==============================================================================


