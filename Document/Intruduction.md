 ==============================================================================
 什么是爬虫？
     互联网海量的数据，用一般的方式已经无法满足对数据的需求了，当你打开浏览器在百度谷歌搜索关键词的时候你就已经间接的使用了爬虫，只不过它并不属于你
     关键词通过通过互联网发送到百度的服务器，这一过程称为Requests（请求），然后百度服务器给你一个Response（响应）
     爬虫其实就是直接向服务器发送Requests，而不需要你的浏览器
     
 
 为什么使用爬虫？
     假设：
         市场调查
         刷评论
         获取资源
     你可能需要：
         点击网页上万次
     或者你有一个通用爬虫，能帮你一键：
         上传
         下载
 怎么编写爬虫？
     简单来说：
         发送请求
         获得服务器发送过来的html代码
         解析html代码，筛选获取有效数据
         保存数据
         分析数据
 ==============================================================================